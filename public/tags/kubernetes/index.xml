<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Sebiwi</title>
    <link>http://localhost:1313/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on Sebiwi</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Dec 2017 08:19:02 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes vs Docker: Volumes!</title>
      <link>http://localhost:1313/blog/kubernetes-vs-docker-volumes/</link>
      <pubDate>Tue, 26 Dec 2017 08:19:02 +0100</pubDate>
      <guid>http://localhost:1313/blog/kubernetes-vs-docker-volumes/</guid>
      <description>&lt;p&gt;&lt;em&gt;This post was co-written by the amazing Pierre-Yves Napoly.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;hey-everybody&#34;&gt;Hey everybody!&lt;/h2&gt;&#xA;&lt;p&gt;After reading both the Kubernetes and Docker “How does it work?” series, I&#xA;suess you can’t wait to transform your old-school infrastructure and put&#xA;all your applications inside containers. Indeed, containers are a great way to&#xA;make your applications portable and easy to deploy. Nevertheless, there is a&#xA;subject we have not discussed yet: data persistence.&lt;/p&gt;&#xA;&lt;p&gt;Before we start, we’d like to say that there are ways to handle data that are&#xA;more cloud-oriented than volumes. These include managed relational database&#xA;services, non-relational database services, and object storage services, all of&#xA;which are easier to operate than volumes, since they harness most of the&#xA;benefits of the cloud ecosystem. Volumes seem to match better &lt;a href=&#34;https://blog.octo.com/en/pet-vs-cattle-from-server-craftsman-to-software-craftsman/&#34;&gt;with pets than&#xA;with cattle&lt;/a&gt; and may be an obstacle to scalability unless you are using read&#xA;only volumes (more on this later). In any case, be sure to regularly backup&#xA;your data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How does it work? Kubernetes! Episode 5 - Master and worker, at last!</title>
      <link>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-5-master-and-worker-at-last/</link>
      <pubDate>Mon, 03 Apr 2017 20:19:02 +0100</pubDate>
      <guid>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-5-master-and-worker-at-last/</guid>
      <description>&lt;h2 id=&#34;lets-install-our-master-node&#34;&gt;Let’s install our Master node!&lt;/h2&gt;&#xA;&lt;p&gt;Absolutely.&lt;/p&gt;&#xA;&lt;p&gt;So basically, we need to create an API server, a Scheduler, and a Controller Manager&#xA;Server on the Master node.&lt;/p&gt;&#xA;&lt;p&gt;First, we&amp;rsquo;ll add the TLS resources needed for the master node. That means the CA&#xA;certificate and the API server certificate and key. Nothing complicated about that.&lt;/p&gt;&#xA;&lt;p&gt;Next up, networking. For this we&amp;rsquo;ll use Flannel and Calico.&lt;/p&gt;&#xA;&lt;p&gt;In order to configure Flannel, we just add configuration environment variables under&#xA;&lt;code&gt;/etc/flannel/options.env&lt;/code&gt;. These specify that the flannel interface is this node&amp;rsquo;s public&#xA;IP, and that the cluster configuration is stocked in etcd cluster:&lt;/p&gt;</description>
    </item>
    <item>
      <title>How does it work? Kubernetes! Episode 4 - How to Ansible your CoreOS, and etc(d)!</title>
      <link>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-4-how-to-ansible-your-coreos-and-etcd/</link>
      <pubDate>Thu, 30 Mar 2017 20:19:02 +0100</pubDate>
      <guid>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-4-how-to-ansible-your-coreos-and-etcd/</guid>
      <description>&lt;h2 id=&#34;can-i-see-the-code-now&#34;&gt;Can I see the code now?&lt;/h2&gt;&#xA;&lt;p&gt;Right, code. The first step is to actually create the CoreOS virtual machines. I used a really&#xA;simple Vagrantfile in which I specify how many instances I want, and how much computing&#xA;resources each one of them is going to have:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# General cluster configuration&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$etcd_instances &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$etcd_instance_memory &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$etcd_instance_cpus &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$kube_master_instances &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$kube_master_instance_memory &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$kube_master_instance_cpus &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$kube_worker_instances &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$kube_worker_instance_memory &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$kube_worker_instance_cpus &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;figcaption class=&#34;caption&#34;&gt;&lt;a href=&#34;https://github.com/sebiwi/kubernetes-coreos/blob/master/Vagrantfile#L4-L13&#34;&gt;Amazing complexity&lt;/a&gt;&lt;/figcaption&gt;&#xA;&lt;p&gt;You can modify the amount of instances you want to create in this part. Be aware that if you&#xA;add hosts, you will also need to add them in the inventory for the Ansible code to target&#xA;all the machines.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How does it work? Kubernetes! Episode 3 - Infrastructure as code: the tools of the trade</title>
      <link>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-3-infrastructure-as-code-the-tools-of-the-trade/</link>
      <pubDate>Fri, 24 Mar 2017 20:19:02 +0100</pubDate>
      <guid>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-3-infrastructure-as-code-the-tools-of-the-trade/</guid>
      <description>&lt;h2 id=&#34;i-understand-the-sdn-related-issues-tell-me-about-infrastructure-as-code-already&#34;&gt;I understand the SDN-related issues. Tell me about Infrastructure as Code already!&lt;/h2&gt;&#xA;&lt;p&gt;Alright. Whenever I think about automating the creation of a platform or an application&#xA;using &lt;a href=&#34;https://en.wikipedia.org/wiki/Infrastructure_as_Code&#34;&gt;Infrastructure as Code&lt;/a&gt;, I think about three different stages: provisioning,&#xA;configuration and deployment.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Provisioning&lt;/strong&gt; is the process of creating the virtual resources in which your application&#xA;or platform will run. The complexity of the resources may vary depending on your platform:&#xA;from simple virtual machines if you&amp;rsquo;re working locally, to something slightly more elaborate&#xA;if you&amp;rsquo;re working on the cloud (network resources, firewalls, and various other services).&lt;/p&gt;</description>
    </item>
    <item>
      <title>How does it work? Kubernetes! Episode 2 - Kubernetes networking</title>
      <link>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-2-kubernetes-networking/</link>
      <pubDate>Fri, 17 Mar 2017 20:19:02 +0100</pubDate>
      <guid>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-2-kubernetes-networking/</guid>
      <description>&lt;h2 id=&#34;i-dont-even-understand-what-the-problem-is-dude&#34;&gt;I don’t even understand what the problem is dude&lt;/h2&gt;&#xA;&lt;p&gt;Well, as I said in the previous article, communication between pods that are&#xA;hosted on different machines can be a little bit tricky. Docker will create by&#xA;default a virtual bridge called “docker0” on the host machine, and it will assign&#xA;a private network range to it.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/how-does-it-work-kube/2/docker-bridge.png&#34; alt=&#34;Docker bridge&#34;&gt;{: class=&amp;ldquo;bigger-image&amp;rdquo; }&lt;/p&gt;&#xA;&lt;figcaption class=&#34;caption&#34;&gt;Super bridge (172.17.0.1/16)&lt;/figcaption&gt;&#xA;&lt;p&gt;For each container that is created, a virtual ethernet device is attached to this bridge,&#xA;which is then mapped to eth0 inside the container, with an ip within the aforementioned network range.&#xA;Note that this will happen for each host that is running Docker, without any coordination between&#xA;the hosts. Therefore, the network ranges might collide.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How does it work? Kubernetes! Episode 1 - Kubernetes general architecture</title>
      <link>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-1-kubernetes-general-architecture/</link>
      <pubDate>Sat, 11 Mar 2017 20:19:02 +0100</pubDate>
      <guid>http://localhost:1313/blog/how-does-it-work-kubernetes-episode-1-kubernetes-general-architecture/</guid>
      <description>&lt;h2 id=&#34;hey-everybody&#34;&gt;Hey everybody&lt;/h2&gt;&#xA;&lt;p&gt;I hacked something together in order to create a Kubernetes cluster on CoreOS&#xA;(or Container Linux) using Vagrant and Ansible.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;If you keep reading, I&amp;rsquo;m going to talk to you about Kubernetes, etcd, CoreOS, flannel,&#xA;Calico, Infrastructure as Code and Ansible testing strategies. It&amp;rsquo;s gonna be super fun.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;The whole subject was way too long for a single article. Therefore, I’ve divided it into 5 parts.&#xA;This is episode 1, regarding the Kubernetes general architecture.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
